---
title: Programming Assignment 3 
author: <Branton Li - 301311707> 
output: 
  html_document:
    mathjax: default 
---

```{r include=FALSE} 
#libraries are loaded here
library("randomForest")
library("pROC")
library("caret")
library("e1071")
library("plyr")
library("dplyr")
library("forecast")
```


```{r}
#preprocessing
titanic <- read.csv(file="titanic3.csv")
titanic <- titanic[-1310,]
train_size <- floor(0.8*nrow(titanic))
set.seed(1)
tmp <- sample(1:nrow(titanic), size=train_size)
t.train <- titanic[tmp,]
t.test <- titanic[-tmp,]

t.train[t.train==""]<-NA
t.test[t.test==""]<-NA

preprocess <- function(name_frame){
  mean_age <- mean(name_frame[,5], na.rm=TRUE)
  mean_fare <- mean(name_frame[,9], na.rm=TRUE)
  name_frame$embarked[is.na(name_frame[,11])] <- "S"
  name_frame$age[is.na(name_frame[,5])] <- mean_age
  name_frame$fare[is.na(name_frame[,9])] <- mean_fare
  name_frame<- name_frame[,-c(3,8,10,12:14)]
  name_frame<- mutate(name_frame,
    pclass = factor(pclass, levels = c(1,2,3), labels = c("Top", "Middle", "Basic")),
    survived = factor(survived, levels = c(0,1), labels = c(FALSE, TRUE))
  )
  return(name_frame)
}

t.train <- preprocess(t.train)
t.test <- preprocess(t.test)
```

## Task 1 
```{r} 
#your code for task 1 comes here 
train.rf <- randomForest(survived ~., data = t.train, ntree=100, importance=TRUE)


rf.class.pred <- predict(train.rf, t.test, type = "class")
table_pred <- table(rf.class.pred, t.test$survived)
accuracy <- sum(diag(table_pred)) / sum(table_pred)
print("accuracy of the random Forest")
print(accuracy)
print(train.rf)

rf.prob.pred <- predict(train.rf, t.test, type = "prob")
plot.roc(t.test$survived, (rf.prob.pred[,1]))
train.auc <- auc(t.test$survived, (rf.prob.pred[,1]))
print("AUC of the ROC curve")
print(train.auc)
``` 
The performance of the best random forest model is worse than the best decision tree from PA2 where the accuracy for the best decision tree is around 0.82.


## Task 2 
```{r} 
#your code for task 2 comes here 
importance(train.rf, type = 1)

varImpPlot(train.rf, type = 1)
```
The top three most important attributes in decreasing order are sex, pclass and fare.

For sex, it is important for classification as female tends to have a higher chance to be survival than male as it is a general rule to put the females to safety first when there is danger. 

For pclass, it is important for classification as passengers of higher pclass may have a possible chance to live close to the escape boats thus easier to get to safety and survive.

For fare, it is important for classification as passengers who pay higher fare may have a higher chance to be of higher pclass thus higher chance to survive. 



## Task 3 
```{r} 
#your code for task 3 comes here 
logistic <- train(survived~., t.train, method="glmnet", family="binomial")
varImp(logistic)
```
The most significant three attributes of the model are pclass, sex and embarked.



## Task 4 
```{r} 
#your code for task 4 comes here 
log.class.pred <- predict(logistic, t.test)
log.table <- table(t.test$survived, log.class.pred)
log.accuracy <- sum(diag(log.table)) / sum(log.table)
print("accuracy of logistic regression model")
print(log.accuracy)

log.prob.pred <- predict(logistic, t.test, type = "prob")
plot.roc(t.test$survived, (log.prob.pred[,1]))
train.auc <- auc(t.test$survived, (log.prob.pred[,1]))
print("AUC of the ROC curve of logistic regression model")
print(train.auc)
```


## Task 5 
```{r} 
#your code for task 5 comes here 
linear.svm <- svm(survived~., t.train, kernel="linear")
radial.svm<- svm(survived~., t.train, kernel="radial")

tuned.linear <- tune.svm(survived ~., data = t.train, cost=10^(-1:2), kernel="linear")
tuned.radial <- tune.svm(survived ~., data = t.train, gamma=c(.5,1,2), kernel="radial")

print(tuned.linear)

print(tuned.radial)
```
since the best parameters for cost and gamma is the smallest value in the given range, we can deduce that the data is spaced far apart such that the margin in between the two groups is very large.


## Task 6 
```{r} 
#your code for task 6 comes here 
tuned.svm <- svm(survived ~ ., data=t.train, kernel="radial", cost=0.1, gamma=0.5, probability = TRUE)
svm.pred <- predict(tuned.svm, t.test)
svm.table <- table(t.test$survived, svm.pred)
svm.accuracy <- sum(diag(svm.table)) / sum(svm.table)
print("accuracy of svm model")
print(svm.accuracy)

svm.prob.pred <- predict(tuned.svm, t.test, probability = TRUE)

plot.roc(t.test$survived, attr(svm.prob.pred, "probabilities")[,1])
train.auc <- auc(t.test$survived, attr(svm.prob.pred, "probabilities")[,1])
print("AUC of the ROC curve of tuned svm model")
print(train.auc)
```